{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percentages(array):\n",
    "    for j in range(array.shape[1]):\n",
    "        count_col = 0\n",
    "        for i in range(array.shape[0]):\n",
    "            if array[i,j] == -999:\n",
    "                count_col += 1\n",
    "        count_col = (count_col/array.shape[0])*100\n",
    "        print(f'For the feature {j+1} : {count_col} % of missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the matrix (not affected by undetermined values)\n",
    "def standardize(tX, affected = False) :\n",
    "    tX_standardized = tX.copy()\n",
    "    for feature in tX_standardized.T : \n",
    "        mask = (feature != -999)\n",
    "        i_mask = (feature == -999)\n",
    "        if affected :\n",
    "            feature[i_mask] = feature[mask].mean() # replace undetermined value by 0\n",
    "            feature = (feature-feature.mean())/feature.std() # standardize\n",
    "        else :\n",
    "            feature[i_mask] = 0 # replace undetermined value by mean of column\n",
    "            feature[mask] = (feature[mask]-feature[mask].mean())/feature[mask].std() # standardize\n",
    "    tX_standardized.T[22] = tX.T[22]\n",
    "    return tX_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the matrix (affected by undetermined values)\n",
    "tX_standardized = standardize(tX)\n",
    "tX_standardized_af = standardize(tX, affected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask removing columns with unvalid data\n",
    "remove_na_mask = []\n",
    "for j in range(tX.shape[1]):\n",
    "    remove_na_mask.append(not (-999 in tX[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask removing columns with unvalid data except the first one because it has only 15% on error\n",
    "remove_error_mask = []\n",
    "for j in range(tX.shape[1]):\n",
    "    remove_error_mask.append(not (-999 in tX[:,j]))\n",
    "remove_error_mask[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask removing all columns with unvalid or 0 data\n",
    "remove_all_mask = []\n",
    "for j in range(tX.shape[1]):\n",
    "    remove_all_mask.append(not (-999 in tX[:,j]))\n",
    "remove_all_mask[29] = False\n",
    "remove_all_mask[22] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cols = tX_standardized[:, remove_error_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, feature in enumerate(tX.T) :\n",
    "#    print(\"Feature \" , i+1)\n",
    "#    plt.plot(feature[:1000], y[:1000], 'kp', alpha = 0.002)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.08857600e-03 -2.43302526e-01 -2.17501064e-01  2.26245355e-03\n",
      "  2.46368227e-01 -2.79541103e-02 -4.43537328e+02 -1.90530411e-01\n",
      "  1.84650059e-01  8.60730569e+01 -9.82652830e-04 -9.88798041e-04\n",
      "  8.48395551e+01  1.06768311e-03  2.85590374e-03  5.86321062e-02\n",
      "  9.48365178e-04 -6.98304497e-02 -2.26372605e-01  3.75921349e+02] 0.3710326238032113\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(clean_cols.shape[1])\n",
    "lambda_ = 50\n",
    "weights, loss = least_squares(y, clean_cols)\n",
    "print(weights, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0 = np.zeros(30)\n",
    "w_0[remove_error_mask] = weights\n",
    "weights = w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize tX_test\n",
    "tX_test_standardized = standardize(tX_test)\n",
    "tX_test_standardized_af = standardize(tX_test, affected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse  0.8614320911171247\n",
      "mse  0.37103262380321117\n",
      "loss found  0.3710326238032113\n"
     ]
    }
   ],
   "source": [
    "rmse_loss = compute_rmse(y, tX_standardized, weights)\n",
    "mse_loss = compute_mse(y, tX_standardized, weights)\n",
    "print('rmse ', rmse_loss)\n",
    "print('mse ', mse_loss)\n",
    "print('loss found ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission_file.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_standardized)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
