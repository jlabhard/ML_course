{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percentages(array):\n",
    "    for j in range(array.shape[1]):\n",
    "        count_col = 0\n",
    "        for i in range(array.shape[0]):\n",
    "            if array[i,j] == -999:\n",
    "                count_col += 1\n",
    "        count_col = (count_col/array.shape[0])*100\n",
    "        print(f'For the feature {j+1} : {count_col} % of missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the matrix (not affected by undetermined values)\n",
    "def standardize(tX, affected = False) :\n",
    "    tX_standardized = tX.copy()\n",
    "    for feature in tX_standardized.T : \n",
    "        mask = (feature != -999)\n",
    "        i_mask = (feature == -999)\n",
    "        if affected :\n",
    "            feature[i_mask] = feature[mask].mean() # replace undetermined value by 0\n",
    "            feature = (feature-feature.mean())/feature.std() # standardize\n",
    "        else :\n",
    "            feature[i_mask] = 0 # replace undetermined value by mean of column\n",
    "            feature[mask] = (feature[mask]-feature[mask].mean())/feature[mask].std() # standardize\n",
    "    tX_standardized.T[22] = tX.T[22]\n",
    "    return tX_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the matrix (affected by undetermined values)\n",
    "tX_standardized = standardize(tX)\n",
    "tX_standardized_af = standardize(tX, affected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask removing columns with unvalid data\n",
    "remove_na_mask = []\n",
    "for j in range(tX.shape[1]):\n",
    "    remove_na_mask.append(not (-999 in tX[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask removing all columns with unvalid or 0 data\n",
    "remove_all_mask = []\n",
    "for j in range(tX.shape[1]):\n",
    "    remove_all_mask.append(not (-999 in tX[:,j]))\n",
    "remove_all_mask[29] = False\n",
    "remove_all_mask[22] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cols = tX_standardized[:, remove_na_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, feature in enumerate(tX.T) :\n",
    "#    print(\"Feature \" , i+1)\n",
    "#    plt.plot(feature[:1000], y[:1000], 'kp', alpha = 0.002)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.29807435e-03 -3.33837373e-03 -4.11087771e-04  1.17229552e-01\n",
      " -1.72596844e-03 -3.15300979e+00 -3.16695463e-01  1.24537010e-01\n",
      "  3.15622641e+00 -7.44030239e-04 -1.12894830e-03  3.16597942e+00\n",
      "  3.09221308e-04  7.21687868e-04  2.06236580e-03  4.95856184e-04\n",
      " -1.06989918e-03  1.70005593e-02  3.15338848e+00] 0.36243002340702934\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(clean_cols.shape[1])\n",
    "lambda_ = 50\n",
    "weights, loss = least_squares(y, clean_cols)\n",
    "print(weights, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0 = np.zeros(30)\n",
    "w_0[mask] = weights\n",
    "weights = w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse  0.851387130989222\n",
      "mse  0.36243002340702934\n",
      "loss found  0.36243002340702934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.79564754, -0.65633087, -0.2681402 , ...,  0.01219161,\n",
       "        0.14272404, -0.64825036])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_loss = compute_rmse(y, tX, weights)\n",
    "mse_loss = compute_mse(y, tX, weights)\n",
    "print('rmse ', rmse_loss)\n",
    "print('mse ', mse_loss)\n",
    "print('loss found ', loss)\n",
    "np.dot(tX_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission_file.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
