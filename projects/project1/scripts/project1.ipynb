{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percentages(array):\n",
    "    for j in range(array.shape[1]):\n",
    "        count_col = 0\n",
    "        for i in range(array.shape[0]):\n",
    "            if array[i,j] == -999:\n",
    "                count_col += 1\n",
    "        count_col = (count_col/array.shape[0])*100\n",
    "        print(f'For the feature {j+1} : {count_col} % of missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the matrix (not affected by undetermined values)\n",
    "def standardize(tX, affected = False) :\n",
    "    tX_standardized = tX.copy()\n",
    "    for feature in tX_standardized.T : \n",
    "        mask = (feature != -999)\n",
    "        i_mask = (feature == -999)\n",
    "        if affected :\n",
    "            feature[i_mask] = feature[mask].mean() # replace undetermined value by 0\n",
    "            feature = (feature-feature.mean())/feature.std() # standardize\n",
    "        else :\n",
    "            feature[i_mask] = 0 # replace undetermined value by mean of column\n",
    "            feature[mask] = (feature[mask]-feature[mask].mean())/feature[mask].std() # standardize\n",
    "    tX_standardized.T[22] = tX.T[22]\n",
    "    tX_standardized = np.c_[tX_standardized, np.ones((tX.shape[0], 1))]\n",
    "    return tX_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the matrix (affected by undetermined values)\n",
    "tX_standardized = standardize(tX)\n",
    "tX_standardized_af = standardize(tX, affected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask removing columns with unvalid data\n",
    "remove_na_mask = []\n",
    "for j in range(tX.shape[1]):\n",
    "    remove_na_mask.append(not (-999 in tX[:,j]))\n",
    "remove_na_mask.append(True) # for 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask removing columns with unvalid data except the first one because it has only 15% on error\n",
    "remove_error_mask = []\n",
    "for j in range(tX.shape[1]):\n",
    "    remove_error_mask.append(not (-999 in tX[:,j]))\n",
    "remove_error_mask[0] = True\n",
    "remove_error_mask.append(True) # for 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask removing all columns with unvalid or 0 data\n",
    "remove_all_mask = []\n",
    "for j in range(tX.shape[1]):\n",
    "    remove_all_mask.append(not (-999 in tX[:,j]))\n",
    "remove_all_mask[29] = False\n",
    "remove_all_mask[22] = False\n",
    "remove_all_mask.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cols = tX_standardized[:, remove_error_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, feature in enumerate(tX.T) :\n",
    "#    print(\"Feature \" , i+1)\n",
    "#    plt.plot(feature[:1000], y[:1000], 'kp', alpha = 0.002)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares with columns removed except the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.08857600e-03 -2.43302526e-01 -2.17501064e-01  2.26245355e-03\n",
      "  2.46368227e-01 -2.79541103e-02 -4.43537328e+02 -1.90530411e-01\n",
      "  1.84650059e-01  8.60730569e+01 -9.82652830e-04 -9.88798041e-04\n",
      "  8.48395551e+01  1.06768311e-03  2.85590374e-03  5.86321062e-02\n",
      "  9.48365178e-04 -6.98304497e-02 -2.26372605e-01  3.75921349e+02] 0.3710326238032113\n"
     ]
    }
   ],
   "source": [
    "tX_temp = tX_standardized[:, remove_error_mask]\n",
    "initial_w = np.zeros(tX_temp.shape[1])\n",
    "lambda_ = 50\n",
    "weights, loss = least_squares(y, tX_temp)\n",
    "# 0.729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0 = np.zeros(tX_standardized.shape()[1])\n",
    "w_0[remove_error_mask] = weights\n",
    "weights = w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with columns removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = remove_error_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.84043912e-02 -6.71104315e-01 -7.49953184e-01  2.48061317e-01\n",
      "  9.01329899e-01 -1.27324944e-01  1.01086845e-01 -5.47784895e-01\n",
      "  3.13594652e-01  5.10059010e-01 -6.83250136e-03 -7.66132644e-04\n",
      "  7.16562082e-01  2.08196349e-03  1.16018058e-03  1.43002568e-01\n",
      " -1.94516843e-03 -1.92393116e-01  1.51221828e-01 -1.58606074e-01\n",
      " -1.00222206e+00]\n"
     ]
    }
   ],
   "source": [
    "tX_temp = tX_standardized[:, mask]\n",
    "initial_w = np.zeros(tX_temp.shape[1])\n",
    "x_train, x_test, y_train, y_test = split_data(tX_temp, y, 0.5, seed = 1)\n",
    "weights, loss = logistic_regression(y_train, x_train, initial_w, 1000, 0.000001)\n",
    "print(weights)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73876"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_labels(weights, x_test)\n",
    "np.count_nonzero(y_test == y_pred) / (y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0 = np.zeros(tX_standardized.shape[1])\n",
    "w_0[remove_all_mask] = weights\n",
    "weights = w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize tX_test\n",
    "tX_test_standardized = standardize(tX_test)\n",
    "tX_test_standardized_af = standardize(tX_test, affected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse  0.8614320911171247\n",
      "mse  0.37103262380321117\n",
      "loss found  0.3710326238032113\n"
     ]
    }
   ],
   "source": [
    "rmse_loss = compute_rmse(y, tX_standardized, weights)\n",
    "mse_loss = compute_mse(y, tX_standardized, weights)\n",
    "print('rmse ', rmse_loss)\n",
    "print('mse ', mse_loss)\n",
    "print('loss found ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission_file.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_standardized)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
